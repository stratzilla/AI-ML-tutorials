{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Neural Network Tutorial\n",
    "\n",
    "This is a tutorial to implement a feedforward neural network using a genetic algorithm to train the network. The \"go-to\" approach for training a neural network is typically backpropagation but there is merit to experimenting with metaheuristics to optimize network weights.\n",
    "\n",
    "I've previously written a tutorial on both <a href=\"../neural-network\">neural networks (using backpropagation)</a> and <a href=\"../genetic-algorithms\">genetic algorithms</a> and in my genetic algorithms tutorial I mentioned some applications of genetic algorithms which included training a neural network. I want to integrate my two tutorials into one and show how a neural network can be trained using a genetic algorithm taking the place of backpropagation.\n",
    "\n",
    "This tutorial does presuppose you've read the linked tutorials as I won't be retreading what a neural network is or does, or how genetic algorithms work. I only explain my implementation of a genetic algorithm trained neural network and whatever may be involved with that. Feel free to distribute, edit, make changes, improve, etc. this tutorial. If you publish this tutorial elsewhere, please let me know and link back.\n",
    "\n",
    "## Neural Networks\n",
    "\n",
    "Without a complete retread of my neural network tutorial, you should know that for the purpose of this tutorial, our neural network is simply a series of weights between neurons. Unlike with backpropagation training, where the network stored neural error deltas and outputs alongside their weights, we only really care about the weights. However, the neural network doesn't optimize the synapse weights, rather we rely on the metaheuristic instead for this purpose.\n",
    "\n",
    "## Genetic Algorithms\n",
    "\n",
    "For our neural network, we use a genetic algorithm to train the network. How? Genetic algorithms need a search space and fitness function (along with genetic parameters like crossover, mutation rates, etc.). A genetic algorithm is an optimizer, and a neural network using backpropagation operates in a similar way: over time, training using backpropagation will optimize the weights such that we minimize some error or loss function, such as the mean squared error. As accuracy in classification is inversely proportional to the error, a lower error means higher accuracy. \n",
    "\n",
    "To this end, we'll be using a genetic algorithm to minimize the mean squared error function using the search space of the weights. In other words, we optimize the weights of the network to reduce the error. The search space bounds aren't known a priori but we'll make some informed assumptions about the problem later. We do, however, know the search space is the possibilities of weights for the network.\n",
    "\n",
    "Like a typical genetic algorithm, we know our search space and fitness function and we can generate a population of candidate solutions and evolve them over time. A candidate solution, or chromosome, in the population will be represented as a set of weights. Once our genetic algorithm is done, we simply encode the chromosome into a set of weights which we then initialize the network as.\n",
    "\n",
    "### Pseudocode\n",
    "\n",
    "Pseudocode for the algorithm is as below:\n",
    "\n",
    "```\n",
    "procedure ga-nn() is:\n",
    "  initialize network strcutrue\n",
    "  initialize random population p of size n\n",
    "  for each epoch do:\n",
    "    sort p by fitness\n",
    "    select elites e from p\n",
    "    select tournament t from p\n",
    "    sort t by fitness\n",
    "    clear contents of p\n",
    "    initialize mating pool m\n",
    "    add e to m and p\n",
    "    add t[0] to m\n",
    "    for i in range 0..(n- 0.size)/2 do:\n",
    "      select two random parents p1, ps2 from m\n",
    "      initialize empty child c1, c2\n",
    "      c1 := crossover(p1, p2)\n",
    "      c2 := crossover(p1, p2)\n",
    "      mutate(c1)\n",
    "      mutate(c2)\n",
    "      add c1, c2 to p\n",
    "    endfor\n",
    "  endfor\n",
    "  network weights := best from p  \n",
    "endprocedure\n",
    "```\n",
    "\n",
    "Note this is identical to the pseudocode for the genetic algorithm as found in that tutorial with the only addition being the best from population serves as weight initialization for the network.\n",
    "\n",
    "## Before you Begin\n",
    "\n",
    "Thus tutorial uses Python and two non-standard dependencies:\n",
    "\n",
    "- Python 3.6\n",
    "- GNU/Linux (or WSL, LXSS, etc)\n",
    "- X11 or alternative\n",
    "- `matplotlib`\n",
    "- `pandas`\n",
    "- some data\n",
    "\n",
    "We'll be using `matplotlib` to graph the mean squared error and model accuracy over time but otherwise doesn't need this library. I use it for illustrative purposes but you can omit it if you don't wish to verify the system works. `pandas` is used for a very important step: normalizing the data. The algorithm will work without it but at a detriment.\n",
    "\n",
    "As for the data, I will be using the Wheat Seeds data set (see `/data`) but the implementation will be data agnostic. Since the network's input and output layer structures are dependent on the data, it will be generalized to take any data set and adjust the model as necessary.\n",
    "\n",
    "## Loading the Data\n",
    "\n",
    "Before implementing the network and metaheuristic, we need to handle how data is loaded and stored.\n",
    "\n",
    "The Wheat Seeds data set consists of 210 examples of 7-dimensional data (seven continuous features per row) along with a discrete classification (three classes). We'll split the data into training and testing sets with a 70%/30% ratio. This means the network is trained on 70% of the data and tested upon the remaining 30%.\n",
    "\n",
    "For our genetic algorithm to work, we need to know the search space. While we know the search space is the set of possible weight permutations, we don't yet know the boundaries of the search space. In fact, there's no declarative way to determine the space boundaries but we can make an informed guess that the weights will be relatively small and of similar magnitudes. We'll normalize our input data around `0` to shrink the total search space and make an assumption the weights will be within `[-3.00, 3.00]`.\n",
    "\n",
    "Here we'll load the data, normalize it, and then split it into our training and testing portions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import floor, ceil\n",
    "\n",
    "def load_data(filename):\n",
    "    \"\"\"Loads CSV for splitting into training and testing data.\n",
    "    \n",
    "    Parameters:\n",
    "        filename : the filename of the file to load.\n",
    "    \n",
    "    Returns:\n",
    "        Two lists, each corresponding to training and testing data.\n",
    "    \"\"\"\n",
    "    # load into pandas dataframe\n",
    "    df = pd.read_csv(filename, header=None, dtype=float)\n",
    "    # normalize the data\n",
    "    for features in range(len(df.columns)-1):\n",
    "        df[features] = (df[features] - df[features].mean())/df[features].std()\n",
    "    train = df.sample(frac=0.70).fillna(0.00) # get training portion\n",
    "    test = df.drop(train.index).fillna(0.00) # remainder testing portion\n",
    "    return train.values.tolist(), test.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above function, we load the CSV into a master dataframe, normalize the features, then take a random 70% sample as training data and use the remaining as testing data. We'll output the number of examples for each to verify as well as find the number of columns in the data (attributes) and the number of unique classifications in the data (classes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples: 147\n",
      "Testing examples: 63\n",
      "\n",
      "Features: 7, Classes: 3\n"
     ]
    }
   ],
   "source": [
    "# get training/testing data\n",
    "TRAIN, TEST = load_data('./data/wheat.csv')\n",
    "\n",
    "print(f'Training examples: {len(TRAIN)}')\n",
    "print(f'Testing examples: {len(TEST)}')\n",
    "\n",
    "# count number of attributes\n",
    "FEATURES = len(TRAIN[0][:-1])\n",
    "# count number of unique classifications\n",
    "CLASSES = len(list(set([c[-1] for c in (TRAIN+TEST)])))\n",
    "\n",
    "print(f'\\nFeatures: {FEATURES}, Classes: {CLASSES}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is congruent with what we know about the data set in terms of features and classes. We'll use these counts when initializing the network shortly as we want the input layer size to match the number of attributes and the output layer to match the number of unique classifications. The input and output layers are a consequence of the data and not user defined.\n",
    "\n",
    "## Initializing the Network\n",
    "\n",
    "Since we know the size of the input and output layers, we need only come up with a hidden layer size to begin network initialization. We'll use eight hidden neurons in our lone hidden layer giving us a `7-8-3` network structure.\n",
    "\n",
    "Later on we'll need a way to encode a chromosome to use as weights for the network, so our network initializer will take this into consideration. We're still using bias for our network, so each of our chromosomes will need to be `h * (n+1) + o * (h+1)` long, where `n` is the size of our input layer, `h` our hidden layer, and `o` our output layer. For our `7-8-3` network, this means chromosomes will be of length `91`.\n",
    "\n",
    "Here is our network initializer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 8\n",
    "\n",
    "def initialize_network(c, n=FEATURES, h=HIDDEN_SIZE, o=CLASSES):\n",
    "    \"\"\"Neural network initializer.\n",
    "    \n",
    "    Parameters:\n",
    "        c : the chromosome to encode into the network.\n",
    "        n : the number of input neurons.\n",
    "        h : the number of hidden neurons.\n",
    "        o : the number of output neurons.\n",
    "    \n",
    "    Returns:\n",
    "        The n-h-o neural network.\n",
    "    \"\"\"\n",
    "    chr = iter(c) # make iterator from c\n",
    "    neural_network = [] # initially an empty list\n",
    "    # there are (n * h) connections between input layer and hidden layer\n",
    "    neural_network.append([[next(chr) for i in range(n+1)] for j in range(h)])\n",
    "    # there are (h * o) connections between hidden layer and output layer\n",
    "    neural_network.append([[next(chr) for i in range(h+1)] for j in range(o)])\n",
    "    return neural_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like how a network should have its weights initialized within some small range such as `[-1.00, 1.00]` or `[0.00, 1.00]`, the initial chromosomes should be much the same. Right now we'll make a sample chromosome and output the network structure to verify it's working as intended:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1528, -0.1815,  0.1821, -0.8125, -0.3839,  0.7349,  0.9300, -0.1337]\n",
      "[ 0.5811, -0.7446,  0.6616, -0.7300, -0.2670, -0.9829,  0.6506,  0.6974]\n",
      "[-0.1812, -0.4661, -0.2924,  0.5708,  0.4378,  0.3506,  0.5579, -0.8190]\n",
      "[-0.3167,  0.0967, -0.6212,  0.1855, -0.5138,  0.5325,  0.3319,  0.4833]\n",
      "[ 0.4245,  0.6106, -0.3908, -0.0650,  0.3148,  0.0144, -0.4458,  0.4413]\n",
      "[ 0.0962, -0.2165, -0.3902,  0.2854, -0.3361,  0.7763,  0.1200,  0.5133]\n",
      "[ 0.0565, -0.9461, -0.1226,  0.2350,  0.1641, -0.6342, -0.3815,  0.4601]\n",
      "[-0.1506,  0.6724,  0.2020,  0.2757,  0.0317, -0.3052,  0.2001,  0.2122]\n",
      "\n",
      "[-0.0540,  0.8749, -0.2194, -0.5846,  0.4507,  0.8495, -0.8175, -0.6932,  0.8858]\n",
      "[-0.4282, -0.4970, -0.5103,  0.5976,  0.2769,  0.8606,  0.4901, -0.9824,  0.2385]\n",
      "[ 0.5372, -0.2250,  0.2035, -0.9608,  0.0369,  0.3600, -0.2761,  0.5125, -0.3623]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "CHROMOSOME_SIZE = (HIDDEN_SIZE * (FEATURES+1)) + \\\n",
    "    (CLASSES * (HIDDEN_SIZE+1))\n",
    "\n",
    "SAMPLE_CHROMOSOME = [round(random.uniform(-1.00, 1.00),4) \\\n",
    "    for _ in range(CHROMOSOME_SIZE)]\n",
    "\n",
    "NETWORK = initialize_network(SAMPLE_CHROMOSOME)\n",
    "\n",
    "for layer in NETWORK:\n",
    "    for neuron in layer:\n",
    "        print(neuron)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've truncated it for readability. What you should take from this is there are two layers of connections (between the input and hidden layers, and between the hidden and output layers). For the first set of weights, there is a set for each of the neurons in the hidden layer (`8`), each consisting of `8` weights (`7` from input layer + `1` bias). For the second set of weights, there is a set for each of the neurons in the output layer (`3`), each of `9` weights (`8` from hidden layer + `1` bias). \n",
    "\n",
    "This is congruent with our expected structure, however seeing the structure is not terribly important right now.\n",
    "\n",
    "## Fitness Function\n",
    "\n",
    "So far, we have a way to encode the candidate solution into a network but not a way to test how well the network performs. We've established our fitness function will be the mean squared error function, and to this end, we need to implement some of the busywork involved with any feedforward neural network.\n",
    "\n",
    "We'll need to feed data forward into the network (it is a feedforward network after all) to calculate the mean squared error, so much of the below is just an implementation of those requirements.\n",
    "\n",
    "### Summing and Activation Functions\n",
    "\n",
    "The summing function takes neural inputs and aggregates them to be sent to the next layer. In our network, for example, one of the hidden neurons takes eight inputs and needs to create one output from it. To this end, we use a summing function to concatenate them by using the weighted sum of the neural inputs. Each input will contribute a different amount to the output and we use the synapse weights to determine this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summing_function(weights, inputs):\n",
    "    \"\"\"Sums the synapse weights with inputs and bias.\n",
    "    \n",
    "    Parameters:\n",
    "        weights : synaptic weights.\n",
    "        inputs : a vector of inputs.\n",
    "    \n",
    "    Returns:\n",
    "        The aggregate of inputs times weights, plus bias.\n",
    "    \"\"\"\n",
    "    # bias is the final value in the weight vector\n",
    "    bias = weights[-1]\n",
    "    summ = 0.00 # to sum\n",
    "    for i in range(len(weights)-1):\n",
    "        # aggregate the weights with input values\n",
    "        summ += (weights[i] * float(inputs[i]))\n",
    "    return summ + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the weighted sum of the neural inputs, this sum is transferred to an activation function. This function determines the neuron activation or firing: for linear activations, this is a binary \"ON\" or \"OFF\", whereas with non-linear activations, it's a degree of \"ON\".\n",
    "\n",
    "We'll use the rectified linear unit activation function:\n",
    "\n",
    "$$\\text{ReLU}(z) = \\left\\{ \\begin{array}{ll} z & \\text{if }z \\geq 0 \\\\ 0 & \\text{if }z \\lt 0 \\end{array} \\right.$$\n",
    "\n",
    "We can implement this like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "\n",
    "def activation_function(z):\n",
    "    \"\"\"ReLU activation function.\n",
    "    \n",
    "    Parameters:\n",
    "        z : summed output of neuron.\n",
    "    \n",
    "    Returns:\n",
    "        The neuron activation based on the summed output.\n",
    "    \"\"\"\n",
    "    return z if z >= 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've chosen ReLU because some of the problems inherent with ReLU, such as vanishing gradient or dead neurons are a non-issue when we're not using the activation derivative. ReLU is a great activation function when these issues are non-existent, which makes it the perfect candidate for our activation function.\n",
    "\n",
    "We can plot this function to see what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = range(-10, 10+1, 1)\n",
    "y = [activation_function(z) for z in x]\n",
    "plt.plot(x, y, c='blue', lw='1')\n",
    "plt.ylabel('ReLU(z)')\n",
    "plt.xlabel('z')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note it's a combination of linear ($f(x) = x$) and constant ($f(x) = 0$) functions. A negative signal is clamped to zero but otherwise unperturbed.\n",
    "\n",
    "Now we've determined how a neuron will accept an input and produce an output. These two functions are all we need to implement our feedforward function.\n",
    "\n",
    "### Feedforward Function\n",
    "\n",
    "For our feedforward function, we only needed the summation and activation functions as previously defined. Data is fed into the network starting at the first layer, it is processed by the neurons in the input layer, neural outputs are calculated as a function of the data, the neuron's weighted sum of the data, and this value transferred to the activation function. Then, the next layer takes those outputs as inputs and the process cycles until you reach the output layer.\n",
    "\n",
    "Since we don't need to store outputs within the neurons (as would be the case for backpropagation), the feedforward function need only return a value and not mutate the network in any way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(network, example):\n",
    "    \"\"\"Feedforward method. Feeds data forward through network.\n",
    "    \n",
    "    Parameters:\n",
    "        network : the neural network.\n",
    "        example : an example of data to feed forward.\n",
    "    \n",
    "    Returns:\n",
    "        The output of the forward pass.\n",
    "    \"\"\"\n",
    "    layer_input, layer_output = example, []\n",
    "    for layer in network:\n",
    "        for neuron in layer:\n",
    "            # sum the weight with inputs\n",
    "            summ = summing_function(neuron, layer_input)\n",
    "            # activate the sum, append output to outputs\n",
    "            layer_output.append(activation_function(summ))\n",
    "        # inputs become outputs of previous layer\n",
    "        layer_input, layer_output = layer_output, []\n",
    "    return layer_input # return the final output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've done all of this because our error function demands the use of data being fed into the network to calculate the network error.\n",
    "\n",
    "### Mean Squared Error\n",
    "\n",
    "Now that we can feedforward data through the network, we can implement our error function, the mean squared error. The mean squared error function will feed all training data into the network and find the average error between them. The error is calculated as a function of what is known about the data (the classification is already known) versus what the network outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sse(actual, target):\n",
    "    \"\"\"Sum of Squared Error.\n",
    "    \n",
    "    Parameters:\n",
    "        actual : network output.\n",
    "        target : example target output.\n",
    "    \n",
    "    Returns:\n",
    "        The sum of squared error of the network for an example.\n",
    "    \"\"\"\n",
    "    summ = 0.00\n",
    "    for i in range(len(actual)):\n",
    "        summ += (actual[i] - target[i])**2\n",
    "    return summ\n",
    "\n",
    "def mse(network, training=TRAIN):\n",
    "    \"\"\"Mean Squared Error.\n",
    "    \n",
    "    Parameters:\n",
    "        network : the neural network to test.\n",
    "        training : a set of training data to test with.\n",
    "    \"\"\"\n",
    "    summ = 0.00\n",
    "    # for each training example\n",
    "    for example in training:\n",
    "        # populate a target vector\n",
    "        target = [0 for _ in range(CLASSES)]\n",
    "        # denote correct classification\n",
    "        target[int(example[-1])] = 1\n",
    "        # get actual output by feeding example through network\n",
    "        actual = feed_forward(network, example)\n",
    "        # sum up the sum of squared error\n",
    "        summ += sse(actual, target)\n",
    "    # MSE is just sum(sse)/number of examples\n",
    "    return summ / len(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the mean squared error is simply the mean of the sum of squared error per training example. This gives us the network error considering every training example.\n",
    "\n",
    "## The Genetic Part\n",
    "\n",
    "So far, we've only been fooling around with the neural network side of things when the brunt of this tutorial will instead focus on the genetic algorithm portion. Up to this point we've only found our fitness function.\n",
    "\n",
    "As previously mentioned, we're using a genetic algorithm to train the network. This is a misnomer, as the use of a metaheuristic such as a genetic algorithm instead tries to find weights and doesn't update weights as an informed decision. It is, however, an informed search. We look at a population of weights, see which works the best, and make new populations which are variations of the prior population's best. To compare, a random search wouldn't be informed whereas a genetic algorithm makes decisions which ensure we get a better fitness over time.\n",
    "\n",
    "### Representing Chromosomes\n",
    "\n",
    "A chromosome for our algorithm is some encoding of network weights. Given a network, we need a way to represent it as a single array or list to make mutation and crossover easier later. To this end we'll consider a chromosome as a containerization of a network by storing its weights as an array or list as well as its fitness (as we don't want to do needless fitness calculations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chromosome:\n",
    "    \"\"\"Chromosome class.\n",
    "    Containerizes genes for chromosome.\n",
    "    \n",
    "    Attributes:\n",
    "        genes : the weights of the network.\n",
    "        fit : the fitness of the chromosome.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, genes, fit=None):\n",
    "        \"\"\"Chromosome constructor without fitness.\"\"\"\n",
    "        # initialize weights from parameter\n",
    "        self.genes = genes\n",
    "        # if no argument passed as fitness\n",
    "        # take fitness from genes argument\n",
    "        # else init as fit argument\n",
    "        if fit is None:\n",
    "            network = initialize_network(self.genes)\n",
    "            self.fit = mse(network)\n",
    "        else:\n",
    "            self.fit = fit\n",
    "    \n",
    "    def set_genes(self, genes):\n",
    "        \"\"\"Genes mutator method.\"\"\"\n",
    "        self.genes = genes\n",
    "        # when setting genes subsequent times\n",
    "        # update the fitness\n",
    "        network = initialize_network(self.genes)\n",
    "        self.fit = mse(network)\n",
    "    \n",
    "    def get_genes(self):\n",
    "        \"\"\"Genes accessor method.\"\"\"\n",
    "        return self.genes\n",
    "    \n",
    "    def get_fit(self):\n",
    "        \"\"\"Fitness accessor method.\"\"\"\n",
    "        return self.fit\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        \"\"\"Less-than operator overload.\"\"\"\n",
    "        return self.fit < other.fit\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"List index operator overload.\"\"\"\n",
    "        return self.genes[key]\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"List length operator overload.\"\"\"\n",
    "        return len(self.genes)\n",
    "    \n",
    "    def __str__(self):\n",
    "        \"\"\"Printing operator overload.\"\"\"\n",
    "        return str(self.genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we have our chromosome genes representing network weights. We can directly check the fitness of a chromosome by decoding it into a network structure. We only check the fitness sometimes, however, as the fitness function is costly: if a chromosome is made as empty, fitness is calculated, otherwise it initializes fitness from parameter.\n",
    "\n",
    "### Population Initialization\n",
    "\n",
    "What we've done so far is we've defined our search space (weights), a fitness function (MSE), and showed how our chromosomes are represented. We don't know the bounds of the search space but it doesn't really matter. We first need a way to generate an initial population. We previously made a sample chromosome which was a chromosome of length `91` and had genes initialized as a random decimal value within the interval `[-0.50, 0.50]`. We'll use this knowledge for our population initialization. \n",
    "\n",
    "Our search space is in `91` dimensions, or the length of each chromosome, but we'll implement the population initializer as being dimensionality agnostic. We'll use a population of `50` for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "POP_SIZE = 50 # the population size\n",
    "\n",
    "def initialize_population(size, dim):\n",
    "    \"\"\"Initializes a random population.\n",
    "    \n",
    "    Parameters:\n",
    "        size : the size of the population.\n",
    "        dim : the dimensionality of the problem\n",
    "    \n",
    "    Returns:\n",
    "        A random population of that many points.\n",
    "    \"\"\"\n",
    "    population = [] # population stored as a list\n",
    "    for _ in range(size): # for the size of the population\n",
    "        genes = [random.uniform(-1.00, 1.00) for _ in range(dim)] # random genes\n",
    "        chromosome = Chromosome(genes) # create the chromosome\n",
    "        population.append(chromosome) # add to population\n",
    "    return population\n",
    "\n",
    "POPULATION = initialize_population(POP_SIZE, CHROMOSOME_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a way to sort the population. Before when we defined our chromosome class structure, we implemented a \"less than\" operator overload for this purpose. This makes sorting a one-line affair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "POPULATION.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to see some of the most fit chromosomes, we'll make a short function to output the five best chromosomes along with their fitness. This function can be expensive because we reinitialize the network weights per chromosome but this is solely for this tutorial and the final code won't include this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chromosome 1 = 0.7167595229431896\n",
      "Chromosome 2 = 0.8228743884288151\n",
      "Chromosome 3 = 0.8340461398929171\n",
      "Chromosome 4 = 1.0308903661707902\n",
      "Chromosome 5 = 1.077302716412207\n"
     ]
    }
   ],
   "source": [
    "def print_five_best():\n",
    "    for i in range(5):\n",
    "        print(f'Chromosome {i+1} = {POPULATION[i].get_fit()}')\n",
    "\n",
    "print_five_best()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we know the most fit chromosomes, the neural network portion takes a back seat and we apply our genetic operators and selection strategies to the population.\n",
    "\n",
    "### Mating Pool Selection\n",
    "\n",
    "The mating pool reflects the chromosomes which will create the new generation's population. We'll be using elites and tournaments. First, we'll get the elites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "def elite_selection(population, percent):\n",
    "    \"\"\"Elite selection function.\n",
    "    Stores elites to bring into the next generation and mating pool.\n",
    "    \n",
    "    Parameters:\n",
    "        population : the population to take elites from.\n",
    "        percent : the proportion of the population to consider elites.\n",
    "    \n",
    "    Returns:\n",
    "        A list of elite solutions.\n",
    "    \"\"\"\n",
    "    elites = []\n",
    "    # grab percent% best individuals\n",
    "    for i in range(ceil(len(population)*percent)):\n",
    "        elites.append(population[i]) # and append to elites\n",
    "    return elites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proportion of elites should be empirically found but we'll use 5% for the sake of example. The proportion of elites should be small, within `[1, 5]` percent. Once an elite is added to the population, we no longer want them in the rest of the population or we may skew our tournament later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MATING_POOL = []\n",
    "ELITES = elite_selection(POPULATION, 0.05)\n",
    "MATING_POOL.extend(ELITES)\n",
    "\n",
    "del POPULATION[:len(ELITES)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's no point in printing the elites as these can be seen if you scroll up a little. \n",
    "\n",
    "We'll then select a tournament and tournament winner from remaining chromosomes in the population. A tournament is some proportion of the population like elites, but instead of taking the most fit individuals, we'll take random individuals, sort them by fitness, and return the winner of the tournament. This means less fit individuals can still impact the next generation, as we want some diversity in our chromosomes.\n",
    "\n",
    "The proportion of tournament entrants should also be empirically found but it should be fairly small, such as within the interval `[1, 5]`. We'll use 2%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tournament_selection(population, percent):\n",
    "    \"\"\"Tournament selection function.\n",
    "    Creates a tournament of random individuals and returns the best.\n",
    "    \n",
    "    Parameters:\n",
    "        population : the population to take tournament from.\n",
    "        percent : the proportion of the population who enters the tournament.\n",
    "    \n",
    "    Returns:\n",
    "        Best fit individual from tournament.\n",
    "    \"\"\"\n",
    "    tournament = []\n",
    "    # grab percent% random individuals\n",
    "    for i in range(ceil(len(population)*percent)):\n",
    "        random_idx = random.randint(0, len(population)-1)\n",
    "        tournament.append(population.pop(random_idx)) # append to tournament\n",
    "    tournament.sort() # sort by fitness\n",
    "    return tournament[0] # return best fit from tournament"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise we add these to the mating pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOURNAMENT = tournament_selection(POPULATION, 0.02)\n",
    "MATING_POOL.append(TOURNAMENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have our mating pool and can discredit the remainder of the population. We'll be making a new one soon using the chromosomes from the mating pool.\n",
    "\n",
    "### Evolving the Population\n",
    "\n",
    "Now we can evolve the population by performing our genetic operators. The two operators being used are crossover and mutation, the specific flavor of each being two-point and uniform respectively. These genetic operators will allow the new population to be generated from combinations from chromosomes in the mating pool while still introducing some random diversity through mutation.\n",
    "\n",
    "First, we'll implement the two-point crossover operator. Two-point crossover combines parent chromosomes based on pivot points: when recombining parents to form children, genes are taken from one parent up to the first pivot point, from the second until the second pivot point, then from the first parent again until the end of the chromosome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def crossover(parent_a, parent_b, cr):\n",
    "    \"\"\"Two-point crossover operator.\n",
    "    \n",
    "    Parameters:\n",
    "        parent_a : the first parent.\n",
    "        parent_b : the second parent.\n",
    "        cr : the crossover chance.\n",
    "    \n",
    "    Returns:\n",
    "        Two child chromosomes as a product of both parents.\n",
    "    \"\"\"\n",
    "    # only perform crossover based on the crossover rate\n",
    "    if random.uniform(0.00, 1.00) >= cr:\n",
    "        child_a = Chromosome(parent_a.get_genes(), parent_a.get_fit())\n",
    "        child_b = Chromosome(parent_b.get_genes(), parent_b.get_fit())\n",
    "        return child_a, child_b\n",
    "    genes_a, genes_b = [], []\n",
    "    # find pivot points at random 1..n-1\n",
    "    pivot_a = random.randint(1, len(parent_a)-1)\n",
    "    # second pivot is between pivot_a..n-1\n",
    "    pivot_b = random.randint(pivot_a, len(parent_a)-1)\n",
    "    for i in range(0, len(parent_a)):\n",
    "        # before first pivot, use genes from one parent\n",
    "        if i < pivot_a:\n",
    "            genes_a.append(parent_a[i])\n",
    "            genes_b.append(parent_b[i])\n",
    "        # before second pivot, use genes from second parent\n",
    "        elif i < pivot_b:\n",
    "            genes_a.append(parent_b[i])\n",
    "            genes_b.append(parent_a[i])\n",
    "        # after second pivot, use genes from first parent again\n",
    "        else:\n",
    "            genes_a.append(parent_a[i])\n",
    "            genes_b.append(parent_b[i])\n",
    "    return Chromosome(genes_a), Chromosome(genes_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While crossover allows children to be part of each parent, we don't want the population to be strictly based on the mating pool. Were the mating pool to contain only poorly fit individuals, this means the algorithm never improves towards more fit individuals. To this end we need a way to reintroduce diversity: using mutation.\n",
    "\n",
    "We're using a Gaussian mutation operator. This is where the mutation will perturb a chromosome by altering a gene to be a random position within a normal distribution. Since our chromosomes were initialized randomly within the interval `[-1.00, 1.00]` and our chromosome doesn't widen the range of genes, we need to consider when the search space is outside of this interval. We need an exploratory factor which can allow some genes to be perturbed outside this interval, but rarely.\n",
    "\n",
    "To grab from the normal distribution, we'll use the mean as the mean of all genes in the chromosome and a sigma of `0.9`. This means there's an approximately 57% chance a gene is perturbed outside `[-0.50, 0.50]`, a 26% chance outside `[-1.00, 1.00]`, and so on if the chromosome average were `0`. This allows the chromosome average to shift away from `0`, which then changes the distribution for later generations, etc.\n",
    "\n",
    "Thus, if an optimal gene is outside our initialization range, it can still be found given a little effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(child, mr):\n",
    "    \"\"\"Mutation operator.\n",
    "    \n",
    "    Parameters:\n",
    "        child : the chromosome to mutate.\n",
    "        mr : the mutation chance.\n",
    "    \n",
    "    Returns:\n",
    "        A mutated child.\n",
    "    \"\"\"\n",
    "    # the new genes to make\n",
    "    genes = [gene for gene in child.get_genes()]\n",
    "    # gene average\n",
    "    avg = sum(genes) / len(genes)\n",
    "    for i in range(len(genes)):\n",
    "        # only perform mutation based on the mutation rate\n",
    "        if random.uniform(0.00, 1.00) <= MUTAT_RATE:\n",
    "            # update that axes with random position\n",
    "            genes[i] = random.gauss(mu=avg, sigma=0.9)\n",
    "    # we don't need to update the fitness if the gene\n",
    "    # hasn't changed, so only update genes if they've changed\n",
    "    if genes != child.get_genes():\n",
    "        child.set_genes(genes)\n",
    "    return child"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we're mutating on a per gene basis, not per chromosome. This means each gene has a chance to mutated rather than just a chromosome has a chance to mutate.\n",
    "\n",
    "Once we have our crossover and mutation operators defined, we can make a driver for the evolutionary part of the algorithm. We'll also define dummy crossover and mutation rate variables to test our evolution algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "CROSS_RATE = 0.90\n",
    "MUTAT_RATE = 0.20\n",
    "\n",
    "def evolve(mating_pool, elites, pop_size, cr, mr):\n",
    "    \"\"\"Evolves population based on genetic operators.\n",
    "    \n",
    "    Parameters:\n",
    "        mating_pool : where to select parents from.\n",
    "        elites : previously found elites.\n",
    "        pop_size : the population size.\n",
    "        cr : crossover rate.\n",
    "        mr : mutation rate.\n",
    "    \n",
    "    Returns:\n",
    "        A new population of offspring from mating pool.\n",
    "    \"\"\"\n",
    "    new_population = [] # store new population as list\n",
    "    new_population += elites # add elites verbatim\n",
    "    while len(new_population) < pop_size: # while population isn't at max size\n",
    "        # get both parents indices\n",
    "        p_a_idx = random.randrange(len(mating_pool))\n",
    "        p_b_idx = random.randrange(len(mating_pool))\n",
    "        # we don't mind parents having identical genes but we don't\n",
    "        # want the parents to use the same index. Parent A can be\n",
    "        # equal to Parent B, but Parent A cannot be Parent B\n",
    "        if p_a_idx == p_b_idx:\n",
    "            continue\n",
    "        # get the parents from indices\n",
    "        parent_a = mating_pool[p_a_idx]\n",
    "        parent_b = mating_pool[p_b_idx]\n",
    "        # find children using crossover\n",
    "        child_a, child_b = crossover(parent_a, parent_b, cr)\n",
    "        # mutate each child\n",
    "        child_a = mutation(child_a, mr)\n",
    "        child_b = mutation(child_b, mr)\n",
    "        # add children to population\n",
    "        new_population += [child_a, child_b]\n",
    "    return new_population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try out our evolution algorithm by comparing the best five best candidates initially versus after one step of evolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before evolution:\n",
      "Chromosome 1 = 1.0308903661707902\n",
      "Chromosome 2 = 1.077302716412207\n",
      "Chromosome 3 = 1.1025679850503154\n",
      "Chromosome 4 = 1.1501852236126175\n",
      "Chromosome 5 = 1.1998086917667854\n",
      "\n",
      "After evolution:\n",
      "Chromosome 1 = 0.7167595229431896\n",
      "Chromosome 2 = 0.7345072994004964\n",
      "Chromosome 3 = 0.8164335736703942\n",
      "Chromosome 4 = 0.8228743884288151\n",
      "Chromosome 5 = 0.8340461398929171\n"
     ]
    }
   ],
   "source": [
    "print('Before evolution:')\n",
    "print_five_best()\n",
    "\n",
    "POPULATION = evolve(MATING_POOL, ELITES, POP_SIZE, \\\n",
    "    CROSS_RATE, MUTAT_RATE)\n",
    "POPULATION.sort()\n",
    "\n",
    "print('\\nAfter evolution:')\n",
    "print_five_best()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see just looking at a sample of the five best chromosomes in the population, they've all improved somewhat, converging closer to optimum.\n",
    "\n",
    "Our evolution driver will use our selection strategies (elites and tournament) to devise a mating pool and then create the new population using our genetic operators.\n",
    "\n",
    "## Other Performance Measures\n",
    "\n",
    "Our goal with using the genetic algorithm to train our network is to optimize the weights such that the mean squared error function is minimized. We know classification accuracy is (roughly) inversely proportional to the mean squared error but we should examine this as well. We'll use this to make a nice graph later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_measure(chromosome, data):\n",
    "    \"\"\"Measures accuracy of the network using classification error.\n",
    "    \n",
    "    Parameters:\n",
    "        chromosome : the chromosome to test.\n",
    "        data : a set of data examples.\n",
    "    Returns:\n",
    "        A percentage of correct classifications.\n",
    "    \"\"\"\n",
    "    network = initialize_network(chromosome)\n",
    "    correct, total = 0, 0\n",
    "    for example in data:\n",
    "        # check to see if the network output matches target output\n",
    "        if check_output(network, example) == float(example[-1]):\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    return 100*(correct / total)\n",
    "\n",
    "def check_output(network, example):\n",
    "    \"\"\"Compares network output to actual output.\n",
    "    \n",
    "    Parameters:\n",
    "        network : the neural network.\n",
    "        example : an example of data.\n",
    "    Returns:\n",
    "        The class the example belongs to (based on network guess).\n",
    "    \"\"\"\n",
    "    output = feed_forward(network, example)\n",
    "    return output.index(max(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just another way for us to look at the network performance. We could even use the classification accuracy as our genetic algorithm fitness function but it is safer to use the mean squared error for this reason instead.\n",
    "\n",
    "## Main Driver\n",
    "\n",
    "That's everything we need to implement: we've successfully made a neural network which can train using a genetic algorithm. Below we'll make a main driver to drive population initialization, evolution, and network initialization from best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELITE_PROPORTION = 0.05 # proportion of elites\n",
    "TOURN_PROPORTION = 0.03 # proportion of tournament\n",
    "EPOCHS = 100 # how many generations\n",
    "CROSS_RATE = 0.90 # crossover rate\n",
    "MUTAT_RATE = 0.05 # mutation rate\n",
    "POP_SIZE = 100 # how large a population is\n",
    "\n",
    "MSE = [] # to store MSE over epochs\n",
    "TRP = [] # training accuracy over epochs\n",
    "TEP = [] # testing accuracy over epochs\n",
    "\n",
    "def genetic_network(el_p, to_p, dim, epochs, pop_size, cr, mr):\n",
    "    \"\"\"Genetic Neural Network training function.\n",
    "    \n",
    "    Parameters:\n",
    "        el_p : the proportion of elites\n",
    "        to_p : the proportion of tournament\n",
    "        dim : dimensionality of network.\n",
    "        epochs : how many generations to run.\n",
    "        pop_size : the population size.\n",
    "        cr : crossover rate.\n",
    "        mr : mutation rate.\n",
    "    \n",
    "    Returns:\n",
    "        A trained neural network.\n",
    "    \"\"\"\n",
    "    # initialize network as initially random\n",
    "    population = initialize_population(pop_size, dim)\n",
    "    for e in range(1, epochs+1):\n",
    "        # sort the population by fitness\n",
    "        population.sort()\n",
    "        # get fitness of network\n",
    "        MSE.append(population[0].get_fit())\n",
    "        # training accuracy of network\n",
    "        TRP.append(performance_measure(population[0].get_genes(), TRAIN))\n",
    "        # testing accuracy of network\n",
    "        TEP.append(performance_measure(population[0].get_genes(), TEST))\n",
    "        mating_pool = [] # init mating pool\n",
    "        # get elites from population\n",
    "        elites = elite_selection(population, el_p)\n",
    "        del population[:len(elites)] # remove elites\n",
    "        # find tournament and winner\n",
    "        t_winner = tournament_selection(population, to_p)\n",
    "        # add tournament victor and elites to mating pool\n",
    "        mating_pool.extend(elites)\n",
    "        mating_pool.append(t_winner)\n",
    "        # generate a new population based on mating pool\n",
    "        population = evolve(mating_pool, elites, pop_size, cr, mr)\n",
    "        mating_pool.clear() # clear mating pool for next gen\n",
    "    population.sort()\n",
    "    return initialize_network(population[0].get_genes())\n",
    "\n",
    "# initialize network as trained from genetic algorithm\n",
    "NETWORK = genetic_network(ELITE_PROPORTION, TOURN_PROPORTION, \\\n",
    "    CHROMOSOME_SIZE, EPOCHS, POP_SIZE, CROSS_RATE, MUTAT_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have three global lists, `MSE`, `TRP`, and `TEP` to store the mean squared error, training performance, and testing performance per epoch of the algorithm. We can plot these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_data():\n",
    "    x = range(0, EPOCHS)\n",
    "    fig, ax2 = plt.subplots()\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('MSE', color='blue')\n",
    "    line, = ax2.plot(x, MSE, '-', c='blue', lw='1', label='MSE')\n",
    "    ax1 = ax2.twinx()\n",
    "    ax1.set_ylabel('Accuracy (%)', color='green')\n",
    "    line2, = ax1.plot(x, TRP, '-', c='green', lw='1', label='Training')\n",
    "    line3, = ax1.plot(x, TEP, ':', c='green', lw='1', label='Testing')\n",
    "    fig.tight_layout()\n",
    "    fig.legend(loc='center')\n",
    "    ax1.set_ylim(0, 101)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "plot_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see over time the mean squared error is diminished, just as it would were you using backpropagation; as the mean squared error is inversely proportional to the accuracy of the network, you also see accuracy rise.\n",
    "\n",
    "## Final Thoughts\n",
    "\n",
    "It's interesting to think about a metaheuristic like genetic algorithms in training a network. A lot of literature and even what you may have learned in school were you to take a computer science degree use genetic algorithms in different ways. At least for me, using one to train a neural network isn't standard curriculum but it still has merit to its study.\n",
    "\n",
    "Using this method to train a neural network, we can achieve mostly comparable results. What I didn't mention in this tutorial is how slow it can be compared to backpropagation. However, depending on parameter choices, it tends to converge faster but not necessarily to the same found optimum. It would be useful to define some termination condition (for example, terminate if MSE is below a certain threshold) as often you do not need to run for many epochs but this is problem specific.\n",
    "\n",
    "Further consideration should be given to the activation function used. ReLU has many pitfalls in backpropagation trained networks but performs great in metaheuristic trained networks. I chose it specifically because this is one scenario where there are few drawbacks to doing so. You should still look into other types of activation functions and other types of genetic operators as I've kept it relatively simple here.\n",
    "\n",
    "Lastly, we should address the search space. Here we've started from `[-0.50, 0.50]` and mutate based on a normal distribution around a chromosome average. If an optimal network weight is outside of this range, it can still be found, it just may take some time. Since the search space is not known a priori, different initialization and mutation intervals should be experimented with but empirically you'll find network weights are typically small within `[-10.00, 10.00]`. Normalizing the training and testing data around `0` can shrink the magnitude of the weights allowing a smaller search space to be used. This is where the guesswork is involved with genetic algorithms for network training.\n",
    "\n",
    "## Finished Code\n",
    "\n",
    "Here is the full uncommented code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import pandas as pd\n",
    "from math import floor, ceil, exp\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "class Chromosome:\n",
    "    def __init__(self, genes, fit=None):\n",
    "        self.genes = genes\n",
    "        if fit is None:\n",
    "            network = initialize_network(self.genes)\n",
    "            self.fit = mse(network)\n",
    "        else:\n",
    "            self.fit = fit\n",
    "\n",
    "    def set_genes(self, genes):\n",
    "        self.genes = genes\n",
    "        network = initialize_network(self.genes)\n",
    "        self.fit = mse(network)\n",
    "\n",
    "    def get_genes(self):\n",
    "        return self.genes\n",
    "\n",
    "    def get_fit(self):\n",
    "        return self.fit\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.fit < other.fit\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.genes[key]\n",
    "\n",
    "def genetic_network(el_p, to_p, dim, epochs, pop_size, cr, mr):\n",
    "    population = initialize_population(pop_size, dim)\n",
    "    for e in range(1, epochs+1):\n",
    "        population.sort()\n",
    "        MSE.append(population[0].get_fit())\n",
    "        TRP.append(performance_measure(population[0].get_genes(), TRAIN))\n",
    "        TEP.append(performance_measure(population[0].get_genes(), TEST))\n",
    "        mating_pool = []\n",
    "        elites = elite_selection(population, el_p)\n",
    "        del population[:len(elites)]\n",
    "        t_winner = tournament_selection(population, to_p)\n",
    "        mating_pool.extend(elites)\n",
    "        mating_pool.append(t_winner)\n",
    "        population = evolve(mating_pool, elites, pop_size, cr, mr)\n",
    "        mating_pool.clear()\n",
    "    population.sort()\n",
    "    return initialize_network(population[0].get_genes())\n",
    "\n",
    "def evolve(mating_pool, elites, pop_size, cr, mr):\n",
    "    new_population = []\n",
    "    new_population += elites\n",
    "    while len(new_population) < pop_size:\n",
    "        p_a_idx = random.randrange(len(mating_pool))\n",
    "        p_b_idx = random.randrange(len(mating_pool))\n",
    "        if p_a_idx == p_b_idx:\n",
    "            continue\n",
    "        parent_a = mating_pool[p_a_idx]\n",
    "        parent_b = mating_pool[p_b_idx]\n",
    "        child_a, child_b = crossover(parent_a, parent_b, cr)\n",
    "        child_a = mutation(child_a, mr)\n",
    "        child_b = mutation(child_b, mr)\n",
    "        new_population += [child_a, child_b]\n",
    "    return new_population\n",
    "\n",
    "def crossover(parent_a, parent_b, cr):\n",
    "    if random.uniform(0.00, 1.00) >= cr:\n",
    "        child_a = Chromosome(parent_a.get_genes(), parent_a.get_fit())\n",
    "        child_b = Chromosome(parent_b.get_genes(), parent_b.get_fit())\n",
    "        return child_a, child_b\n",
    "    genes_a, genes_b = [], []\n",
    "    pivot_a = random.randint(1, len(parent_a.get_genes())-1)\n",
    "    pivot_b = random.randint(pivot_a, len(parent_a.get_genes())-1)\n",
    "    for i in range(0, len(parent_a.get_genes())):\n",
    "        if i < pivot_a:\n",
    "            genes_a.append(parent_a[i])\n",
    "            genes_b.append(parent_b[i])\n",
    "        elif i < pivot_b:\n",
    "            genes_a.append(parent_b[i])\n",
    "            genes_b.append(parent_a[i])\n",
    "        else:\n",
    "            genes_a.append(parent_a[i])\n",
    "            genes_b.append(parent_b[i])\n",
    "    return Chromosome(genes_a), Chromosome(genes_b)\n",
    "\n",
    "def mutation(child, mr):\n",
    "    genes = [gene for gene in child.get_genes()]\n",
    "    avg = sum(genes) / len(genes)\n",
    "    for i in range(len(genes)):\n",
    "        if random.uniform(0.00, 1.00) <= mr:\n",
    "            genes[i] = random.gauss(mu=avg, sigma=0.9)\n",
    "    if genes != child.get_genes():\n",
    "        child.set_genes(genes)\n",
    "    return child\n",
    "\n",
    "def initialize_population(size, dim):\n",
    "    population = []\n",
    "    for _ in range(size):\n",
    "        genes = [random.uniform(-0.50, 0.50) for _ in range(dim)]\n",
    "        chromosome = Chromosome(genes)\n",
    "        population.append(chromosome)\n",
    "    return population\n",
    "\n",
    "def elite_selection(population, percent):\n",
    "    elites = []\n",
    "    for i in range(ceil(len(population)*percent)):\n",
    "        elites.append(population[i])\n",
    "    return elites\n",
    "\n",
    "def tournament_selection(population, percent):\n",
    "    tournament = []\n",
    "    for i in range(ceil(len(population)*percent)):\n",
    "        random_idx = random.randint(0, len(population)-1)\n",
    "        tournament.append(population.pop(random_idx))\n",
    "    tournament.sort()\n",
    "    return tournament[0]\n",
    "\n",
    "def initialize_network(c):\n",
    "    n, h, o = FEATURES, HIDDEN_SIZE, CLASSES\n",
    "    chr = iter(c)\n",
    "    neural_network = []\n",
    "    neural_network.append([[next(chr) for i in range(n+1)] for j in range(h)])\n",
    "    neural_network.append([[next(chr) for i in range(h+1)] for j in range(o)])\n",
    "    return neural_network\n",
    "\n",
    "def feed_forward(network, example):\n",
    "    layer_input, layer_output = example, []\n",
    "    for layer in network:\n",
    "        for neuron in layer:\n",
    "            summ = summing_function(neuron, layer_input)\n",
    "            layer_output.append(activation_function(summ))\n",
    "        layer_input, layer_output = layer_output, []\n",
    "    return layer_input\n",
    "\n",
    "def summing_function(weights, inputs):\n",
    "    \"\"\"Sums the synapse weights with inputs and bias.\n",
    "\n",
    "    Parameters:\n",
    "        weights : synaptic weights.\n",
    "        inputs : a vector of inputs.\n",
    "\n",
    "    Returns:\n",
    "        The aggregate of inputs times weights, plus bias.\n",
    "    \"\"\"\n",
    "    bias = weights[-1]\n",
    "    summ = 0.00\n",
    "    for i in range(len(weights)-1):\n",
    "        summ += (weights[i] * float(inputs[i]))\n",
    "    return summ + bias\n",
    "\n",
    "def activation_function(z):\n",
    "    return z if z >= 0 else 0\n",
    "\n",
    "def performance_measure(chromosome, data):\n",
    "    network = initialize_network(chromosome)\n",
    "    correct, total = 0, 0\n",
    "    for example in data:\n",
    "        if check_output(network, example) == float(example[-1]):\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    return 100*(correct / total)\n",
    "\n",
    "def check_output(network, example):\n",
    "    output = feed_forward(network, example)\n",
    "    return output.index(max(output))\n",
    "\n",
    "def sse(actual, target):\n",
    "    summ = 0.00\n",
    "    for i in range(len(actual)):\n",
    "        summ += (actual[i] - target[i])**2\n",
    "    return summ\n",
    "\n",
    "def mse(network):\n",
    "    training = TRAIN\n",
    "    summ = 0.00\n",
    "    for example in training:\n",
    "        target = [0 for _ in range(CLASSES)]\n",
    "        target[int(example[-1])] = 1\n",
    "        actual = feed_forward(network, example)\n",
    "        summ += sse(actual, target)\n",
    "    return summ / len(training)\n",
    "\n",
    "def load_data(filename):\n",
    "    df = pd.read_csv(filename, header=None, dtype=float)\n",
    "    for features in range(len(df.columns)-1):\n",
    "        df[features] = (df[features] - df[features].mean())/df[features].std()\n",
    "    train = df.sample(frac=0.70).fillna(0.00)\n",
    "    test = df.drop(train.index).fillna(0.00)\n",
    "    return train.values.tolist(), test.values.tolist()\n",
    "\n",
    "def plot_data():\n",
    "    x = range(0, EPOCHS)\n",
    "    fig, ax2 = plt.subplots()\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('MSE', color='blue')\n",
    "    line, = ax2.plot(x, MSE, '-', c='blue', lw='1', label='MSE')\n",
    "    ax1 = ax2.twinx()\n",
    "    ax1.set_ylabel('Accuracy (%)', color='green')\n",
    "    line2, = ax1.plot(x, TRP, '-', c='green', lw='1', label='Training')\n",
    "    line3, = ax1.plot(x, TEP, ':', c='green', lw='1', label='Testing')\n",
    "    fig.tight_layout()\n",
    "    fig.legend(loc='center')\n",
    "    ax1.set_ylim(0, 101)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MSE, TRP, TEP = [], [], []\n",
    "    TRAIN, TEST = load_data('../data/wheat.csv')\n",
    "    FEATURES = len(TRAIN[0][:-1])\n",
    "    CLASSES = len(list(set([c[-1] for c in (TRAIN+TEST)])))\n",
    "    HIDDEN_SIZE = 8\n",
    "    CHROMOSOME_SIZE = (HIDDEN_SIZE * (FEATURES+1)) + \\\n",
    "        (CLASSES * (HIDDEN_SIZE+1))\n",
    "    POP_SIZE = 100\n",
    "    CROSS_RATE, MUTAT_RATE = 0.90, 0.05\n",
    "    ELITE_PROPORTION, TOURN_PROPORTION = 0.05, 0.03\n",
    "    EPOCHS = 200\n",
    "    NETWORK = genetic_network(ELITE_PROPORTION, TOURN_PROPORTION, \\\n",
    "        CHROMOSOME_SIZE, EPOCHS, POP_SIZE, CROSS_RATE, MUTAT_RATE)\n",
    "    plot_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may wish to catch for errors (as I have done none here), and perhaps accept some of the parameters as command line arguments. This code, as-is, should run in a terminal but allows for zero customization unless you change the code manually. Some parameters might include hidden layer size, crossover and mutation rates, how many epochs, etc. This is just a basic implementation to springboard off of and experiment with.\n",
    "\n",
    "You can save this code as `genetic_network.py` and execute it as one of the below:\n",
    "\n",
    "```\n",
    "$ python3 genetic_network.py\n",
    "$ ./genetic_network.py\n",
    "```\n",
    "\n",
    "You can also find the code along with a commented version in `./code`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
