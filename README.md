# Tutorials

This is a collection of machine learning and artificial intelligence tutorials I've written using Jupyter Notebook. They may not be up to snuff with some other tutorials, and in many cases, I've written them after only one or two implementations. I'm keeping these here for posterity for myself and for those who might also be interested. I had a hard time finding tutorials online for some of these subjects, so I thought I'd make my own for those who find themselves in a similar position to what I was.

I try my best to only use Python standard libraries, although I do quite like `numpy`, `pandas`, and `matplotlib`. Some `gnuplot` is involved as well but only for illustrative purposes.

Feel free to distribute, copy, edit, make changes to, etc. these tutorials to your hearts content. All I ask is if you publish any of them elsewhere, please let me know and link back.

### <a href="https://github.com/stratzilla/tutorials/tree/master/genetic-algorithms">Genetic Algorithms</a>

A step-by-step implementation of a genetic algorithm to optimize the Styblinski-Tang function, generalized to any dimensionality. Includes one-point crossover and uniform mutation operators, tournament and elite selection strategies.

### <a href="https://github.com/stratzilla/tutorials/tree/master/particle-swarm-optimization">Particle Swarm Optimization</a>

A step-by-step implementation of a particle swarm algorithm to optimize the Schwefel function, generalized to any dimensionality.

### <a href="https://github.com/stratzilla/tutorials/tree/master/k-means">K-Means Clustering with K-Means++ Initialization Strategy</a>

A step-by-step implementation of a K-Means clustering algorithm using K-Means++ initialization strategy. Includes Dunn Index calculation to determine merit in cluster count optimization.

### <a href="https://github.com/stratzilla/tutorials/tree/master/neural-network">Neural Network using Backpropagation Training</a>

A step-by-step implementation of a vanilla feedforward neural network trained via backpropagation to model a classifier for the Iris data set. Includes learning rate and momentum hyperparameters.

### <a href="https://github.com/stratzilla/tutorials/tree/master/genetic-neural-network">Neural Network using Genetic Algorithm Training</a>

A step-by-step implementation of a feedforward neural network, but instead trained using a genetic algorithm to optimize network weights. It helps to have read the <i>Neural Network using Backpropagation Training</i> and <i>Genetic Algorithms</i> tutorials beforehand.

### <a href="https://github.com/stratzilla/tutorials/tree/master/particle-neural-network">Neural Network using Particle Swarm Optimization Training</a>

A step-by-step implementation of a feedforward neural network, but instead using a particle swarm algorithm to optimize neural weights. It helps to have read the <i>Neural Network using Backpropagation Training</i> and <i>Particle Swarm Optimization</i> tutorials beforehand.

## Stuff I'm Working On

Eventually I hope to add these tutorials at some point (in no particular order):

- color organization using Self Organizing Maps (SOMs)
- simulated annealing metaheuristic
- training a neural network using simulated annealing
